{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b13c2215-deaf-4cc5-b9af-616d0dd79580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54e6dc38-8472-4a47-9b10-ef354174d670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# SQL UDFs\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "* Define and register SQL UDFs\n",
    "* Describe the security model used for sharing SQL UDFs\n",
    "* Use **`CASE`** / **`WHEN`** statements in SQL code\n",
    "* Leverage **`CASE`** / **`WHEN`** statements in SQL UDFs for custom control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a19697a-105a-4bdb-822b-bdba4a9d4824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "  - In the drop-down, select **More**.\n",
    "\n",
    "  - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4411fdc6-6aea-47a9-873d-0abb639a7096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course. It will also set your default catalog to **dbacademy** and the schema to your specific schema name shown below using the `USE` statements.\n",
    "<br></br>\n",
    "\n",
    "\n",
    "```\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA dbacademy.<your unique schema name>;\n",
    "```\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0465be12-f863-469b-a731-b0912c2cd8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table style=\"width:100%\">\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Course Catalog:</td>\n",
       "                <td><input type=\"text\" value=\"dbacademy\" style=\"width: 100%\"></td></tr>\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Your Schema:</td>\n",
       "                <td><input type=\"text\" value=\"labuser9051024_1738251370\" style=\"width: 100%\"></td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./Includes/Classroom-Setup-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3351028e-1f79-4bff-a471-eb0ec6c2a9aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## User-Defined Functions\n",
    "\n",
    "User Defined Functions (UDFs) in Spark SQL allow you to register custom SQL logic as functions in a database, making these methods reusable anywhere SQL can be run on Databricks. These functions are registered natively in SQL and maintain all of the optimizations of Spark when applying custom logic to large datasets.\n",
    "\n",
    "At minimum, creating a SQL UDF requires a function name, optional parameters, the type to be returned, and some custom logic.\n",
    "\n",
    "Below, a simple function named **`sale_announcement`** takes an **`item_name`** and **`item_price`** as parameters. It returns a string that announces a sale for an item at 80% of its original price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2a20b67-90e0-4812-ad91-a4aa5cad85b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>item_id</th><th>name</th><th>price</th><th>message</th></tr></thead><tbody><tr><td>M_PREM_Q</td><td>Premium Queen Mattress</td><td>1795.0</td><td>The Premium Queen Mattress is on sale for $1436</td></tr><tr><td>M_STAN_F</td><td>Standard Full Mattress</td><td>945.0</td><td>The Standard Full Mattress is on sale for $756</td></tr><tr><td>M_PREM_F</td><td>Premium Full Mattress</td><td>1695.0</td><td>The Premium Full Mattress is on sale for $1356</td></tr><tr><td>M_PREM_T</td><td>Premium Twin Mattress</td><td>1095.0</td><td>The Premium Twin Mattress is on sale for $876</td></tr><tr><td>M_PREM_K</td><td>Premium King Mattress</td><td>1995.0</td><td>The Premium King Mattress is on sale for $1596</td></tr><tr><td>P_DOWN_S</td><td>Standard Down Pillow</td><td>119.0</td><td>The Standard Down Pillow is on sale for $95</td></tr><tr><td>M_STAN_Q</td><td>Standard Queen Mattress</td><td>1045.0</td><td>The Standard Queen Mattress is on sale for $836</td></tr><tr><td>M_STAN_K</td><td>Standard King Mattress</td><td>1195.0</td><td>The Standard King Mattress is on sale for $956</td></tr><tr><td>M_STAN_T</td><td>Standard Twin Mattress</td><td>595.0</td><td>The Standard Twin Mattress is on sale for $476</td></tr><tr><td>P_FOAM_S</td><td>Standard Foam Pillow</td><td>59.0</td><td>The Standard Foam Pillow is on sale for $47</td></tr><tr><td>P_FOAM_K</td><td>King Foam Pillow</td><td>79.0</td><td>The King Foam Pillow is on sale for $63</td></tr><tr><td>P_DOWN_K</td><td>King Down Pillow</td><td>159.0</td><td>The King Down Pillow is on sale for $127</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "M_PREM_Q",
         "Premium Queen Mattress",
         1795.0,
         "The Premium Queen Mattress is on sale for $1436"
        ],
        [
         "M_STAN_F",
         "Standard Full Mattress",
         945.0,
         "The Standard Full Mattress is on sale for $756"
        ],
        [
         "M_PREM_F",
         "Premium Full Mattress",
         1695.0,
         "The Premium Full Mattress is on sale for $1356"
        ],
        [
         "M_PREM_T",
         "Premium Twin Mattress",
         1095.0,
         "The Premium Twin Mattress is on sale for $876"
        ],
        [
         "M_PREM_K",
         "Premium King Mattress",
         1995.0,
         "The Premium King Mattress is on sale for $1596"
        ],
        [
         "P_DOWN_S",
         "Standard Down Pillow",
         119.0,
         "The Standard Down Pillow is on sale for $95"
        ],
        [
         "M_STAN_Q",
         "Standard Queen Mattress",
         1045.0,
         "The Standard Queen Mattress is on sale for $836"
        ],
        [
         "M_STAN_K",
         "Standard King Mattress",
         1195.0,
         "The Standard King Mattress is on sale for $956"
        ],
        [
         "M_STAN_T",
         "Standard Twin Mattress",
         595.0,
         "The Standard Twin Mattress is on sale for $476"
        ],
        [
         "P_FOAM_S",
         "Standard Foam Pillow",
         59.0,
         "The Standard Foam Pillow is on sale for $47"
        ],
        [
         "P_FOAM_K",
         "King Foam Pillow",
         79.0,
         "The King Foam Pillow is on sale for $63"
        ],
        [
         "P_DOWN_K",
         "King Down Pillow",
         159.0,
         "The King Down Pillow is on sale for $127"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "item_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CREATE OR REPLACE FUNCTION sale_announcement(item_name STRING, item_price INT)\n",
    "  RETURNS STRING\n",
    "  RETURN concat(\"The \", item_name, \" is on sale for $\", round(item_price * 0.8, 0));\n",
    "\n",
    "\n",
    "SELECT *, \n",
    "  sale_announcement(name, price) AS message \n",
    "FROM item_lookup;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4822fdf-cd5f-4760-8305-9a6a6ffc5ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that this function is applied to all values of the column in a parallel fashion within the Spark processing engine. SQL UDFs are an efficient way to define custom logic that is optimized for execution on Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e1a0f4-79c2-49b6-bc38-2d11217aab8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Scoping and Permissions of SQL UDFs\n",
    "SQL user-defined functions:\n",
    "- Persist between execution environments (which can include notebooks, DBSQL queries, and jobs).\n",
    "- Exist as objects in the metastore and are governed by the same Table ACLs as databases, tables, or views.\n",
    "- To **create** a SQL UDF, you need **`USE CATALOG`** on the catalog, and **`USE SCHEMA`** and **`CREATE FUNCTION`** on the schema.\n",
    "- To **use** a SQL UDF, you need **`USE CATALOG`** on the catalog, **`USE SCHEMA`** on the schema, and **`EXECUTE`** on the function.\n",
    "\n",
    "We can use **`DESCRIBE FUNCTION`** to see where a function was registered and basic information about expected inputs and what is returned (and even more information with **`DESCRIBE FUNCTION EXTENDED`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "547de868-42c6-491a-9e78-6fe4d196e0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>function_desc</th></tr></thead><tbody><tr><td>Function:      dbacademy.labuser9051024_1738251370.sale_announcement</td></tr><tr><td>Type:          SCALAR</td></tr><tr><td>Input:         item_name  STRING</td></tr><tr><td>               item_price INT   </td></tr><tr><td>Returns:       STRING</td></tr><tr><td>Deterministic: true</td></tr><tr><td>Data Access:   CONTAINS SQL</td></tr><tr><td>Configs:       spark.databricks.sql.expression.aiFunctions.repartition=0</td></tr><tr><td>               spark.databricks.sql.functions.aiForecast.enabled=false</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.clusterSizeBasedGlobalParallelism.scaleFactor=32.0</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.debugLogEnabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.enabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize=2048</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSizeForBatch=512</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdCurrentQpsIncreaseRatio=0.0</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdSuccessRatio=0.95</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdTotalQpsIncreaseRatio=0.0</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.taskWaitTimeInSeconds=1000</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.threadKeepAliveTimeInSeconds=600</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.useDynamicTaskQueueExecutor=false</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.batch.aiQuery.embedding.request.size=4</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.batch.execution.size=2048</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.batchInferenceApi.enabled=false</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.decimal.dataType.enabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.model.parameters.enabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.modelEndpointTypeParsing.enabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.remoteHttpClient.maxConnections=2048</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.remoteHttpClient.timeoutInSeconds=360</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.safe.inference.enabled=true</td></tr><tr><td>               spark.databricks.sql.functions.aiFunctions.useDedicatedHttpClient=true</td></tr><tr><td>               spark.databricks.sql.functions.vectorSearch.enabled=true</td></tr><tr><td>               spark.sql.functions.remoteHttpClient.retryOn400TimeoutError=true</td></tr><tr><td>               spark.sql.functions.remoteHttpClient.retryOnSocketTimeoutException=true</td></tr><tr><td>               spark.sql.hive.convertCTAS=true</td></tr><tr><td>               spark.sql.legacy.createHiveTableByDefault=false</td></tr><tr><td>               spark.sql.parquet.compression.codec=snappy</td></tr><tr><td>               spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol</td></tr><tr><td>               spark.sql.sources.default=delta</td></tr><tr><td>               spark.sql.streaming.stopTimeout=15s</td></tr><tr><td>Owner:         labuser9051024_1738251370@vocareum.com</td></tr><tr><td>Create Time:   Thu Jan 30 15:52:38 UTC 2025</td></tr><tr><td>Body:          concat(\"The \", item_name, \" is on sale for $\", round(item_price * 0.8, 0))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Function:      dbacademy.labuser9051024_1738251370.sale_announcement"
        ],
        [
         "Type:          SCALAR"
        ],
        [
         "Input:         item_name  STRING"
        ],
        [
         "               item_price INT   "
        ],
        [
         "Returns:       STRING"
        ],
        [
         "Deterministic: true"
        ],
        [
         "Data Access:   CONTAINS SQL"
        ],
        [
         "Configs:       spark.databricks.sql.expression.aiFunctions.repartition=0"
        ],
        [
         "               spark.databricks.sql.functions.aiForecast.enabled=false"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.clusterSizeBasedGlobalParallelism.scaleFactor=32.0"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.debugLogEnabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.enabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize=2048"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSizeForBatch=512"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdCurrentQpsIncreaseRatio=0.0"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdSuccessRatio=0.95"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdTotalQpsIncreaseRatio=0.0"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.taskWaitTimeInSeconds=1000"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.threadKeepAliveTimeInSeconds=600"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.useDynamicTaskQueueExecutor=false"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.batch.aiQuery.embedding.request.size=4"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.batch.execution.size=2048"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.batchInferenceApi.enabled=false"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.decimal.dataType.enabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.model.parameters.enabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.modelEndpointTypeParsing.enabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.remoteHttpClient.maxConnections=2048"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.remoteHttpClient.timeoutInSeconds=360"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.safe.inference.enabled=true"
        ],
        [
         "               spark.databricks.sql.functions.aiFunctions.useDedicatedHttpClient=true"
        ],
        [
         "               spark.databricks.sql.functions.vectorSearch.enabled=true"
        ],
        [
         "               spark.sql.functions.remoteHttpClient.retryOn400TimeoutError=true"
        ],
        [
         "               spark.sql.functions.remoteHttpClient.retryOnSocketTimeoutException=true"
        ],
        [
         "               spark.sql.hive.convertCTAS=true"
        ],
        [
         "               spark.sql.legacy.createHiveTableByDefault=false"
        ],
        [
         "               spark.sql.parquet.compression.codec=snappy"
        ],
        [
         "               spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol"
        ],
        [
         "               spark.sql.sources.default=delta"
        ],
        [
         "               spark.sql.streaming.stopTimeout=15s"
        ],
        [
         "Owner:         labuser9051024_1738251370@vocareum.com"
        ],
        [
         "Create Time:   Thu Jan 30 15:52:38 UTC 2025"
        ],
        [
         "Body:          concat(\"The \", item_name, \" is on sale for $\", round(item_price * 0.8, 0))"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "function_desc",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DESCRIBE FUNCTION EXTENDED sale_announcement;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72059380-e786-444e-b32b-b7f80d4273a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that the **`Body`** field at the bottom of the function description shows the SQL logic used in the function itself.\n",
    "## Viewing Functions in the Catalog Explorer\n",
    "After we create a function, it is associated with a schema. We can view the functions associated with a schema in the Catalog Explorer. \n",
    "1. Follow [**this link**](explore/data) to open Catalog Explorer in a new tab, or use the **Catalog** link in the left sidebar.\n",
    "1. Run the following cell to obtain the name of your current catalog and schema. Paste your catalog name in the cell marked \"Type to filter.\"\n",
    "1. Drill into the catalog to reveal the list of schemas in the catalog, by clicking the disclosure triangle to the left of the catalog name.\n",
    "1. Drill open the schema.\n",
    "1. Note that there is currently one function associated with the schema: **`sale_announcement`**. Select it and explore information about the function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "265b3aae-49fa-498d-92b0-6ab918f0e27a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_catalog()</th><th>current_schema()</th></tr></thead><tbody><tr><td>dbacademy</td><td>labuser9051024_1738251370</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbacademy",
         "labuser9051024_1738251370"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_catalog()",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_schema()",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECT current_catalog(), current_schema();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e392df1d-ecf2-416e-b609-5e626eff1e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simple Control Flow Functions\n",
    "\n",
    "Combining SQL UDFs with control flow in the form of **`CASE`** / **`WHEN`** clauses provides optimized execution for control flows within SQL workloads. The standard SQL syntactic construct **`CASE`** / **`WHEN`** allows the evaluation of multiple conditional statements with alternative outcomes based on table contents.\n",
    "\n",
    "Here, we demonstrate wrapping this control flow logic in a function that will be reusable anywhere we can execute SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a92266-6436-42a5-9e35-49d206839a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>item_id</th><th>name</th><th>price</th><th>dbacademy.labuser9051024_1738251370.item_preference(name, price)</th></tr></thead><tbody><tr><td>M_PREM_Q</td><td>Premium Queen Mattress</td><td>1795.0</td><td>This is my favorite mattress</td></tr><tr><td>M_STAN_F</td><td>Standard Full Mattress</td><td>945.0</td><td>I'd wait until the Standard Full Mattress is on sale for $756</td></tr><tr><td>M_PREM_F</td><td>Premium Full Mattress</td><td>1695.0</td><td>I'd wait until the Premium Full Mattress is on sale for $1356</td></tr><tr><td>M_PREM_T</td><td>Premium Twin Mattress</td><td>1095.0</td><td>I'd wait until the Premium Twin Mattress is on sale for $876</td></tr><tr><td>M_PREM_K</td><td>Premium King Mattress</td><td>1995.0</td><td>I'd wait until the Premium King Mattress is on sale for $1596</td></tr><tr><td>P_DOWN_S</td><td>Standard Down Pillow</td><td>119.0</td><td>I'd wait until the Standard Down Pillow is on sale for $95</td></tr><tr><td>M_STAN_Q</td><td>Standard Queen Mattress</td><td>1045.0</td><td>This is my default mattress</td></tr><tr><td>M_STAN_K</td><td>Standard King Mattress</td><td>1195.0</td><td>I'd wait until the Standard King Mattress is on sale for $956</td></tr><tr><td>M_STAN_T</td><td>Standard Twin Mattress</td><td>595.0</td><td>I'd wait until the Standard Twin Mattress is on sale for $476</td></tr><tr><td>P_FOAM_S</td><td>Standard Foam Pillow</td><td>59.0</td><td>I don't need a Standard Foam Pillow</td></tr><tr><td>P_FOAM_K</td><td>King Foam Pillow</td><td>79.0</td><td>I don't need a King Foam Pillow</td></tr><tr><td>P_DOWN_K</td><td>King Down Pillow</td><td>159.0</td><td>I'd wait until the King Down Pillow is on sale for $127</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "M_PREM_Q",
         "Premium Queen Mattress",
         1795.0,
         "This is my favorite mattress"
        ],
        [
         "M_STAN_F",
         "Standard Full Mattress",
         945.0,
         "I'd wait until the Standard Full Mattress is on sale for $756"
        ],
        [
         "M_PREM_F",
         "Premium Full Mattress",
         1695.0,
         "I'd wait until the Premium Full Mattress is on sale for $1356"
        ],
        [
         "M_PREM_T",
         "Premium Twin Mattress",
         1095.0,
         "I'd wait until the Premium Twin Mattress is on sale for $876"
        ],
        [
         "M_PREM_K",
         "Premium King Mattress",
         1995.0,
         "I'd wait until the Premium King Mattress is on sale for $1596"
        ],
        [
         "P_DOWN_S",
         "Standard Down Pillow",
         119.0,
         "I'd wait until the Standard Down Pillow is on sale for $95"
        ],
        [
         "M_STAN_Q",
         "Standard Queen Mattress",
         1045.0,
         "This is my default mattress"
        ],
        [
         "M_STAN_K",
         "Standard King Mattress",
         1195.0,
         "I'd wait until the Standard King Mattress is on sale for $956"
        ],
        [
         "M_STAN_T",
         "Standard Twin Mattress",
         595.0,
         "I'd wait until the Standard Twin Mattress is on sale for $476"
        ],
        [
         "P_FOAM_S",
         "Standard Foam Pillow",
         59.0,
         "I don't need a Standard Foam Pillow"
        ],
        [
         "P_FOAM_K",
         "King Foam Pillow",
         79.0,
         "I don't need a King Foam Pillow"
        ],
        [
         "P_DOWN_K",
         "King Down Pillow",
         159.0,
         "I'd wait until the King Down Pillow is on sale for $127"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "item_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"double\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "dbacademy.labuser9051024_1738251370.item_preference(name, price)",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CREATE OR REPLACE FUNCTION item_preference(name STRING, price INT)\n",
    "  RETURNS STRING\n",
    "  RETURN CASE \n",
    "    WHEN name = \"Standard Queen Mattress\" THEN \"This is my default mattress\"\n",
    "    WHEN name = \"Premium Queen Mattress\" THEN \"This is my favorite mattress\"\n",
    "    WHEN price > 100 THEN concat(\"I'd wait until the \", name, \" is on sale for $\", round(price * 0.8, 0))\n",
    "    ELSE concat(\"I don't need a \", name)\n",
    "  END;\n",
    "\n",
    "\n",
    "SELECT *, \n",
    "  item_preference(name, price) \n",
    "FROM item_lookup;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef21a5a9-3b05-44da-a0a4-ca28b138f82a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While the examples provided here are simple, these same basic principles can be used to add custom computations and logic for native execution in Spark SQL. \n",
    "\n",
    "Especially for enterprises that might be migrating users from systems with many defined procedures or custom-defined formulas, SQL UDFs can allow a handful of users to define the complex logic needed for common reporting and analytic queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1460229-adee-41cf-8e92-cdbfb6679765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "6 - SQL UDFs",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}