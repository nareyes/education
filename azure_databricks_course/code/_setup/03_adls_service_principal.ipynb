{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6de3c2e2-8a97-49e9-89cc-da43b0eee7fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Access Azure Data Lake Using Service Principal\n",
    "1. Register Azure AD Applicattion and Service Principal (Create Variables For Client and Tenant ID)\n",
    "2. Generate Secret for Application\n",
    "3. Set Spark Config with App/Client ID, Directory/Tenand ID & Secret (From AD Application)\n",
    "4. Assign Role \"Storage Blob Data Contributor\" or \"Storage Blob Data Reader\" to the Data Lake\n",
    "5. List Contents From a Container\n",
    "6. Read Data from a File\n",
    "\n",
    "***This is the recommended access pattern for internal users.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "\n",
    "client_id = \"\"\n",
    "tenant_id = \"\"\n",
    "secret_value = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables Using Secret Scope\n",
    "\n",
    "client_id = dbutils.secrets.get(scope=<secret_scope>, key=<secret_scope_key>)\n",
    "tenant_id = dbutils.secrets.get(scope=<secret_scope>, key=<secret_scope_key>)\n",
    "secret_value = dbutils.secrets.get(scope=<secret_scope>, key=<secret_scope_key>)\n",
    "service_credential = dbutils.secrets.get(scope=\"<secret_scope>\",key=\"<service_scope_key>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cd1293-2d0a-461f-8186-3a27a0965a96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set Spark Config\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.auth.type.<storage_account_namet>.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.<storage_account_namet>.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.<storage_account_namet>.dfs.core.windows.net\", \"<application_id>\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.<storage_account_name>.dfs.core.windows.net\", <service_credential_client_secret>)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.<storage_account_namet>.dfs.core.windows.net\", \"https://login.microsoftonline.com/<directory_id>/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b234e3b2-68b6-4279-8a04-79698040bca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List Contents From a Container\n",
    "\n",
    "dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "592f3d52-aee6-48c0-aefd-adad3228e79c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List Contents From a Container & Directory\n",
    "\n",
    "dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net/<diretory>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424fdb5f-990a-46a8-8cbc-5f470c4fa72c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using the Display Function\n",
    "\n",
    "display(\n",
    "    dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net/<directory>\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0ed9c9-9e76-453c-b982-0e283d5b22ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Data From a File Using Display Function\n",
    "\n",
    "display(\n",
    "    spark.read.csv(abfss://<container@storage_account_name>.dfs.core.windows.net/<directory>/<file_name>)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-ADLS-Access-Key",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
