{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6de3c2e2-8a97-49e9-89cc-da43b0eee7fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Access Azure Data Lake Using Access Keys\n",
    "1. Set Spark Config\n",
    "2. List Contents From a Container\n",
    "3. Read Data from a File\n",
    "\n",
    "***This is the recommended access pattern for external users.***\n",
    "\n",
    "## SAS Token\n",
    "- Provide fine grained access to the storage\n",
    "- Restrict access to specific resource types/services\n",
    "- Allow specific permissions\n",
    "- Restrict access to specific time periods\n",
    "- Limit access to specific IP addresses\n",
    "- Recommended access pattern for external clients\n",
    "\n",
    "### Create Secret Scopes in DB\n",
    "https://learn.microsoft.com/en-us/azure/databricks/security/secrets/secret-scopes\n",
    "\n",
    "### Create SAS Tokens for Storage Containers\n",
    "https://learn.microsoft.com/en-us/azure/cognitive-services/translator/document-translation/how-to-guides/create-sas-tokens?tabs=Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cd1293-2d0a-461f-8186-3a27a0965a96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set Spark Config\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.<storage-account>.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.<storage-account>.dfs.core.windows.net\", dbutils.secrets.get(scope=\"<scope>\", key=\"<sas-token-key>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Spark Config Using Secret Scope\n",
    "\n",
    "adls_sas_key = dbutils.secrets.get(\n",
    "    scope='<secret_scope>',\n",
    "    key='<secret_scope_key>'\n",
    ")\n",
    "\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.auth.type.<storage_account_name>.dfs.core.windows.net\", \n",
    "    \"SAS\"\n",
    "    )\n",
    "\n",
    "spark.conf.set(\n",
    "    \"fs.azure.sas.token.provider.type.<storage_account_name>.dfs.core.windows.net\", \n",
    "    \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\"\n",
    "    )\n",
    "\n",
    "spark.conf.set(\n",
    "    \"fs.azure.sas.fixed.token.<storage_account_name>.dfs.core.windows.net\",\n",
    "    adls_sas_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b234e3b2-68b6-4279-8a04-79698040bca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List Contents From a Container\n",
    "\n",
    "dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "592f3d52-aee6-48c0-aefd-adad3228e79c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List Contents From a Container & Directory\n",
    "\n",
    "dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net/<diretory>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424fdb5f-990a-46a8-8cbc-5f470c4fa72c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using the Display Function\n",
    "\n",
    "display(\n",
    "    dbutils.fs.ls(\"abfss://<container@storage_account_name>.dfs.core.windows.net/<directory>\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0ed9c9-9e76-453c-b982-0e283d5b22ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Data From a File Using Display Function\n",
    "\n",
    "display(\n",
    "    spark.read.csv(abfss://<container@storage_account_name>.dfs.core.windows.net/<directory>/<file_name>)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-ADLS-Access-Key",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
